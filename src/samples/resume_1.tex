\documentclass[11pt, a4paper]{awesome-cv}

% Configure page margins with geometry
\geometry{left=1.4cm, top=.8cm, right=1.4cm, bottom=1.8cm, footskip=.5cm}
\fontdir[fonts/]
\colorlet{awesome}{awesome-red}

% Set false if you don't want to highlight section with awesome color
\setbool{acvSectionColorHighlight}{true}

% If you would like to change the social information separator from a pipe (|) to something else
\renewcommand{\acvHeaderSocialSep}{\quad\textbar\quad}

%-------------------------------------------------------------------------------
%       CJK (Chinese/Japanese/Korean) Font Support
%-------------------------------------------------------------------------------
% Add Chinese font support using xeCJK
\usepackage{xeCJK}
% Set Chinese fonts (fallback to available system fonts)
\setCJKmainfont{Droid Sans Fallback}
\setCJKsansfont{Droid Sans Fallback}
\setCJKmonofont{Droid Sans Fallback}

%-------------------------------------------------------------------------------
%	PERSONAL INFORMATION
%	Comment any of the lines below if they are not required
%-------------------------------------------------------------------------------
% Available options: circle|rectangle,edge/noedge,left/right
\name{Ye**}{-}
\position{Python}

%-------------------------------------------------------------------------------
\begin{document}

% Print the header with above personal informations
% Give optional argument to change alignment(C: center, L: left, R: right)
\makecvheader[C]

% Print the footer with 3 arguments(<left>, <center>, <right>)
% Leave any of these blank if they are not needed
\makecvfooter
  {\today}
  {Ye** -~~~\textperiodcentered~~~Résumé}
  {\thepage}

%-------------------------------------------------------------------------------
%	CV/RESUME CONTENT
%	Each section is imported separately, open each file in turn to modify content
%-------------------------------------------------------------------------------
\cvsection{Summary}
\begin{cvitems}  \item {Large Model Application Development}  \item {Desired Position: Python @ Nanjing, 50-80K}  \item {Desired Position: Other Backend Development @ Nanjing, 50-80K}  \item {Desired Position: Java @ Nanjing, 50-80K}\end{cvitems}


\cvsection{Skills}
\begin{cvskills}  \cvskill
    {Professional Skills}
    {Languages: Python, Java, Rust (Basic). Frameworks: LangChain, LangGraph, Spring, Akka. System Architecture: LLM Multi-Agent Construction, Multi-threading & Asynchronous Programming, Distributed Task Scheduling.}\end{cvskills}


\cvsection{Professional Experience}
\begin{cventries}  \cventry
    {Java}
  {Beijing ByteDance Technology Co., Ltd.}
    {None}
    {2025.01 - Present}
    {      \begin{cvitems}        \item {Large Model Application Development}      \end{cvitems}    }  \cventry
    {Large Model Algorithms}
  {ByteDance}
    {None}
    {2024.01 - 2025.04}
    {      \begin{cvitems}        \item {Responsible for core module development and system design of multiple AI-driven data analysis platforms, covering data ingestion, scheduling execution, attribution analysis, etc. DataWeaver Canvas}        \item {An AI-assisted canvas-style data analysis tool, supporting multi-source data import, one-click JOIN, scrapbook collection, and natural language analysis capabilities.}        \item {Canvas: An infinite data workspace where almost any data can be imported or pasted as cards. Connections between cards represent upstream/downstream data relationships. Also supports notes, images, Lark docs, etc. Multi-source: DataWeaver supports Fengshen data sources, as well as Excel, CSV, and other common formats. Supports one-click refresh to keep data fresh.}        \item {Scrapbook: Can copy Fengshen links, Excel files directly into the canvas, or copy selected data from any webpage or desktop app. }        \item {One-click Join: Whether you want to join two tables into a wide table, or query details for multiple IDs at once, it can be done with one click.}        \item {AI Intelligent Assistance: Through natural language, complex advanced data analysis functions can be achieved.}        \item {Work Content:}        \item {Responsible for backend development of the data source module, designed and implemented high-performance data ingestion pipeline.}        \item {Adopted Apache Arrow Parquet format for data compression and serialization, combined with Rust Polars library for parsing and conversion of Excel and other formats, significantly improving import efficiency for large data volumes. Participated in server-side design and implementation of AI intelligent analysis module, supporting users to query and get analysis results via natural language, lowering the barrier for non-technical users. Implemented backend logic for scrapbook function, supporting rapid collection and structured pasting of heterogeneous data sources.}        \item {DataWeaver Metric Report is a system for team leaders, frontline operations, and data analysts to solve problems like difficult goal tracking, inefficient analysis collaboration, and scattered data, building an automated, accumulable data metric reporting system.}        \item {Supports visual generation of metric reports, configuration and scheduling within 1 minute. Provides one-stop data flow capabilities including history records, weekly report copying, dashboard/data portal synchronization.}        \item {Automatic Lark push of anomaly warnings and preliminary attribution conclusions upon report updates, improving operation response speed.}        \item {Provides analysis canvas and attribution recording mechanism, accumulating methodology and analysis process, supporting continuous optimization.}        \item {Low access cost, only need to import Fengshen links to generate metrics, greatly reducing repetitive work for analysts and improving cross-role collaboration efficiency.}        \item {Work Content:}        \item {As a backend developer, led the implementation of metric import and configuration functions, supporting users to quickly generate scheduled metric reports by importing Fengshen visualization links, controlling the overall access process within 1 minute.}        \item {Designed and implemented a scheduled scheduling system, supporting custom cycle pulling and refreshing of data, ensuring timeliness and stability of data reports.}        \item {Developed a push robot based on Lark Open Platform, supporting automatic push of anomaly warnings, preliminary attribution analysis, and analysis canvas content, improving team response efficiency.}        \item {Implemented attribution result recording mechanism, users can record anomaly analysis conclusions by replying to the robot in the group, building a traceable metric analysis link.}        \item {The project heavily reused infrastructure and general capabilities from the previous DataWeaver Canvas project, reflecting forward-looking system design and good architecture reusability, helping the team complete the first version R&D and launch within two weeks. DataTalks}        \item {DataTalks is an AI data assistant launched by the ByteDance Data Platform team, supporting users to perform data query and analysis through natural language dialogue. The system is based on Multi-Agent architecture, splitting data analysis tasks into multiple specialized Agents, with a central controller CopilotAgent for task allocation and scheduling, improving overall system flexibility and scalability.}        \item {CopilotAgent: System entry, built based on standard ReAct idea, responsible for global task orchestration and pipeline scheduling.}        \item {DataQueryAgent: Receives user query requests, builds query logic based on neutral Structured Query Language (Semantic Layer), avoiding performance and compatibility issues caused by direct SQL generation, significantly reducing Token consumption and improving generation speed.}        \item {Can convert structured query language to query semantics of Fengshen and other visual data products, improving efficiency of user understanding and modification of query conditions.}        \item {Supports multi-data source (ClickHouse, Hive, etc.) access via MetricLayer, reducing instability caused by SQL conversion between different storage engines, improving system compatibility.}        \item {AdvancedDataAnalysisAgent: Performs secondary analysis on query results, built based on CodeAct idea, responsible for generating Python code to process data. RootCauseAgent: Responsible for user data attribution analysis processing.}        \item {Work Content:}        \item {Implementation of query condition recommendation capability; extracted query condition combinations from semantic query statements, aggregated statistics by user, module, dataset dimensions, built query behavior profiles.}        \item {Wrote high-frequency query combinations into vector database, implementing query condition recommendation based on dataset context, improving user query efficiency and experience.}        \item {AI Insight}        \item {AI Insight is a product for business analysis scenarios, supporting exploratory analysis based on single metrics. Users can freely build analysis paths through Mindmap-like interaction, and the system provides multi-dimensional data attribution capabilities to help gain deep insight into business problems.}        \item {Work Content:}        \item {Development of algorithm scheduling layer, receiving analysis paths configured by users on the frontend, dynamically aggregating data according to different algorithm requirements and routing to corresponding attribution algorithm modules. Introduced Java 21 Virtual Threads (FiberThread) in the scheduling link, significantly improving concurrency processing capability and shortening system response time.}        \item {Designed and implemented module architecture based on Domain Driven Design (DDD), abstracting and decoupling user node configuration (Node), algorithm executor (NodeExecutor) and SQL query executor (SqlExecutor), significantly improving the extensibility of the algorithm module, allowing new algorithms to be accessed and launched within one day on average.}      \end{cvitems}    }  \cventry
    {Java}
  {Alibaba}
    {None}
    {2017.06 - 2024.01}
    {      \begin{cvitems}        \item {Responsible for design and R&D of customer service HR cost control system}        \item {Responsible for design and R&D of general calculation engine in customer service HR domain}      \end{cvitems}    }\end{cventries}


\cvsection{Projects}
\begin{cventries}  \cventry
    {Java}
  {Customer Service Performance & Salary Calculation Engine}
    {None}
    {2021.03 - Present}
    {      \begin{cvitems}        \item {General calculation platform supporting complex business rule configuration, cross-source data query, and high-concurrency calculation.}        \item {Supports expression-based rule calculation and automatic dependency parsing, improving flexibility of rule configuration.}        \item {Supports multi-data source access (such as data warehouse, API, etc.), adapting to metric query needs of different business systems.}        \item {Provides extension mechanism for customized calculation logic, such as SLA components, ranking functions, etc., meeting complex business scenarios.}        \item {Engine has good horizontal scalability, supporting high-concurrency calculation tasks.}        \item {Supports business data isolation, ensuring data security and isolation when used by multiple business lines in parallel.}        \item {Work Content:}        \item {Configuration Management Module: Designed and implemented rule configuration storage system, supporting unified configuration management of expressions, metrics, and business custom functions (such as SLA, ranking), ensuring multi-business data isolation and permission control.}        \item {Dependency Parser: Parses business rule formulas based on topological sorting algorithm, dismantling rules into executable Directed Acyclic Graphs (DAG) for task dependency scheduling.}        \item {Runtime Scheduling System: Built task scheduling and execution framework, supporting dynamic selection of local multi-threading or Akka-based distributed concurrency execution schemes according to task scale, balancing performance and scalability.}      \end{cvitems}    }\end{cventries}


\cvsection{Education}
\begin{cventries}  \cventry
    {Bachelor}
  {Guizhou University}
    {None}
    {2008 - 2012}
    {      \begin{cvitems}        \item {Major: Network Engineering}      \end{cvitems}    }\end{cventries}


%-------------------------------------------------------------------------------
\end{document}
